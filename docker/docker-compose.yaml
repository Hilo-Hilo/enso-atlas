services:
  enso-atlas:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: enso-atlas
    # GPU access via deploy.resources (Compose v2 / Swarm compatible)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      ENSO_CONFIG: /app/config/default.yaml
      TRANSFORMERS_CACHE: /app/cache/huggingface
      HF_HOME: /app/cache/huggingface
      # MIL model configuration
      MIL_ARCHITECTURE: transmil
      MIL_THRESHOLD_CONFIG: /app/models/threshold_config.json
      # Offline mode - set to 1 after models are downloaded
      TRANSFORMERS_OFFLINE: "${TRANSFORMERS_OFFLINE:-0}"
      HF_HUB_OFFLINE: "${HF_HUB_OFFLINE:-0}"
    volumes:
      # Bind mount local data directory with full TCGA embeddings
      - /home/hansonwen/med-gemma-hackathon/data:/app/data
      - /home/hansonwen/med-gemma-hackathon/outputs:/app/outputs
      - atlas-cache:/app/cache
      # Model storage (pre-downloaded)
      - /home/hansonwen/.cache/huggingface:/root/.cache/huggingface
      - /home/hansonwen/med-gemma-hackathon/models:/app/models
      # Source code mount for development (allows live editing)
      - /home/hansonwen/med-gemma-hackathon/src:/app/src:ro
    ports:
      - "7862:7860"
      - "8003:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  atlas-outputs:
    driver: local
  atlas-cache:
    driver: local
  atlas-models:
    driver: local
