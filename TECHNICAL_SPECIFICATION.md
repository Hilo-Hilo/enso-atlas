# Enso Atlas: Technical Specification

## On-Premise Pathology Evidence Engine for Treatment-Response Prediction

**Version:** 2.0.0
**Date:** February 2025
**Authors:** Enso Labs
**Classification:** Technical Documentation -- Hackathon Submission / Investor Review

---

# Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [System Architecture](#2-system-architecture)
3. [Foundation Models](#3-foundation-models)
4. [TransMIL Architecture](#4-transmil-architecture)
5. [Backend API Specification](#5-backend-api-specification)
6. [Agentic Workflow](#6-agentic-workflow)
7. [Database Schema](#7-database-schema)
8. [Frontend Architecture](#8-frontend-architecture)
9. [Config-Driven Project System](#9-config-driven-project-system)
10. [Outlier Detection and Few-Shot Classification](#10-outlier-detection-and-few-shot-classification)
11. [Annotation System](#11-annotation-system)
12. [Heatmap and Overlay System](#12-heatmap-and-overlay-system)
13. [Hospital Deployment Guide](#13-hospital-deployment-guide)
14. [Data Pipeline](#14-data-pipeline)
15. [Security and Compliance](#15-security-and-compliance)
16. [Performance Benchmarks](#16-performance-benchmarks)
17. [Mac Mini Deployment Feasibility](#17-mac-mini-deployment-feasibility)
18. [Known Limitations and Future Work](#18-known-limitations-and-future-work)
19. [Appendices](#19-appendices)

---

# 1. Executive Summary

## 1.1 Project Overview

Enso Atlas is an on-premise pathology evidence engine that predicts treatment response from whole-slide histopathology images (WSIs) using Google's HAI-DEF foundation models. The system is designed for deployment within hospital networks, ensuring that Protected Health Information (PHI) never leaves the premises. It deeply integrates all three Google Health AI Developer Foundations models -- Path Foundation, MedGemma 4B, and MedSigLIP -- with a Transformer-based Multiple Instance Learning (TransMIL) classifier to deliver interpretable, evidence-grounded predictions.

The system manages five specialized TransMIL models through a project-scoped architecture backed by PostgreSQL with junction tables (project_models, project_slides) for flexible many-to-many relationships between projects, slides, and models. A comprehensive annotations system persists pathologist markup to PostgreSQL. Interactive tools including outlier tissue detection and few-shot patch classification operate directly on Path Foundation embeddings, enabling pathologists to interrogate and verify model reasoning without leaving the platform.

The platform addresses a critical gap in precision oncology: determining which patients will respond to specific chemotherapy regimens before treatment begins. Currently, treatment response can only be assessed after multiple cycles of therapy, exposing non-responding patients to unnecessary toxicity and delays in receiving effective alternatives. Enso Atlas provides early, morphology-based predictions from standard H&E-stained tissue slides that are already collected during routine clinical care.

### Mission Statement

To build a modular, model-agnostic pathology evidence platform that gives oncologists, pathologists, and tumor boards the information they need to make better treatment decisions -- while keeping patient data secure and on-premise.

### Design Philosophy: Platform, Not a Demo

Enso Atlas is fundamentally a **modular platform**, not a single-purpose tool. The Google HAI-DEF models (Path Foundation, MedGemma, MedSigLIP) are used to demonstrate the platform's capabilities, but every component is designed to be swapped:

- **Foundation models are config-driven.** Replace Path Foundation with UNI, CONCH, Virchow, DINOv2, or any custom embedding model by editing a YAML file. The system only requires a model name and embedding dimension.
- **Classification models are pluggable.** Any attention-based MIL variant (TransMIL, CLAM, ABMIL) can be registered by dropping in a weights file and adding a config entry. No code changes required.
- **Cancer types are project-defined.** Add lung, breast, prostate, or any other cancer by creating a new project block in the configuration. Labels, thresholds, model assignments, and feature toggles are all per-project.
- **Feature toggles are per-project.** Enable or disable MedGemma reports, MedSigLIP semantic search, or similar case retrieval independently for each project.
- **The UI adapts automatically.** All labels, categories, model lists, and workflow steps derive from the project configuration. No hardcoded cancer types or model IDs exist in the frontend.

### Key Capabilities

- **Treatment-Response Prediction:** Binary classification of platinum sensitivity in high-grade serous ovarian carcinoma (HGSOC) using TransMIL with attention-based evidence -- best AUC 0.879 with optimized threshold 0.9229
- **Multi-Model Ensemble:** Five specialized TransMIL models covering platinum sensitivity (AUC 0.907 full dataset), tumor grade (AUC 0.752), 5-year survival (AUC 0.697), 3-year survival (AUC 0.645), and 1-year survival (AUC 0.639)
- **Evidence Generation:** Per-model attention heatmaps overlaid on WSIs with coverage-based alignment, top-K evidence patches with coordinates, and FAISS-based similar case retrieval
- **Semantic Tissue Search:** MedSigLIP-powered text-to-patch search enabling queries like "tumor infiltrating lymphocytes" or "necrotic tissue" with on-the-fly embedding when cached embeddings are unavailable
- **Outlier Tissue Detector:** Centroid distance analysis on Path Foundation embeddings identifies morphologically unusual patches -- highlighting rare tissue patterns, artifacts, or atypical regions for pathologist review
- **Few-Shot Patch Classifier:** Pathologists define custom tissue classes by selecting example patches on the viewer; a LogisticRegression trained on Path Foundation embeddings classifies all patches in the slide with per-class heatmap overlay
- **Structured Reporting:** MedGemma 4B generates tumor-board-ready reports with morphology descriptions, clinical significance, limitations, and mandatory safety statements
- **Agentic Workflow:** Seven-step AI agent with visible reasoning, SSE streaming, and session memory for follow-up questions
- **Pathologist Annotations:** SVG-based drawing tools (circle, rectangle, freehand, point) on the OpenSeadragon viewer with full CRUD persistence to PostgreSQL
- **Batch Analysis:** Async batch processing with model selection, embedding level (L0/L1), force re-embed, real-time progress tracking, and cancellation support
- **PDF Export:** Professional PDF reports suitable for clinical documentation and tumor board presentations
- **Project Management:** Config-driven multi-cancer support with CRUD API and junction table architecture

## 1.2 HAI-DEF Model Integration

Enso Atlas deeply integrates all three Google Health AI Developer Foundations models, going far beyond a simple wrapper:

| HAI-DEF Model | Integration Depth |
|---|---|
| **Path Foundation** | 384-dim embeddings are the universal representation: TransMIL classification, FAISS retrieval, outlier detection (centroid distance), few-shot classification (LogisticRegression), attention heatmaps, and batch re-embedding |
| **MedGemma 4B** | Structured clinical report generation with JSON-first prompting, safety validation, decision support integration, async generation with progress tracking, and template fallback |
| **MedSigLIP** | Text-to-patch semantic search with on-the-fly embedding, predefined pathology query sets, image-to-image visual search via FAISS, and GPU-accelerated batch embedding |

## 1.3 Target Users

| User Role | Primary Use Case | Key Features |
|---|---|---|
| Medical Oncologist | Treatment planning, tumor board discussion | Oncologist summary view, decision support, confidence scores, PDF reports |
| Pathologist | Slide review, morphology verification | WSI viewer with heatmap overlay, annotation tools (SVG on OSD), pathologist view, outlier detector, few-shot classifier |
| Tumor Board | Multidisciplinary case discussion | PDF reports, similar case comparison, batch analysis, multi-model ensemble |
| Clinical Researcher | Cohort analysis, biomarker discovery | Batch analysis, semantic search, project system, slide manager with filtering |
| Hospital IT | Deployment, maintenance | Docker Compose, on-premise, PostgreSQL, health checks, Tailscale Funnel access |

## 1.4 Clinical Contribution

The primary clinical contribution is predicting platinum-based chemotherapy sensitivity in high-grade serous ovarian carcinoma from standard H&E tissue slides:

| Metric | Value |
|---|---|
| Best single-model AUC (full dataset) | 0.879 |
| Full-dataset AUC (all 208 slides) | 0.907 |
| Optimized threshold (Youden J) | 0.9229 |
| Sensitivity | 84.6% |
| Specificity | 91.2% |
| Training cohort | 208 TCGA ovarian cancer slides |
| Class ratio | 139 non-responders : 13 responders |
| Embedding model | Path Foundation (ViT-S, 384-dim) |
| Classification model | TransMIL (3.2M parameters) |

This is not just a score -- Enso Atlas provides the complete evidence chain: attention heatmaps showing which tissue regions drove the prediction, similar cases from the reference cohort for comparison, semantic search for specific tissue patterns, outlier detection for unusual morphology, and structured MedGemma reports with limitations and safety statements.

## 1.5 Competition Landscape

| Feature | Enso Atlas | Paige.ai | PathAI | Google DeepMind |
|---|---|---|---|---|
| On-Premise | Yes (required) | Cloud + Edge | Cloud | Research only |
| Foundation Models | Path Foundation + MedGemma + MedSigLIP (all 3 HAI-DEF) | Proprietary | Proprietary | Internal |
| Explainability | Attention heatmaps + evidence patches + semantic search + outlier detection + few-shot classifier + structured reports | Limited | Moderate | Research |
| Treatment Response | Yes (platinum sensitivity) | Cancer detection | Drug response (research) | N/A |
| Interactive Tools | Outlier detector, few-shot classifier, annotation system | None | Limited | N/A |
| Open Architecture | Config-driven, extensible | Closed | Closed | N/A |
| Cost | Open source / self-hosted | SaaS subscription | SaaS subscription | N/A |

---

# 2. System Architecture

## 2.1 High-Level Architecture

```mermaid
graph TB
    subgraph "Frontend (Next.js 14)"
        UI[React UI - Port 3002]
        OSD[OpenSeadragon WSI Viewer]
        GRID[Patch Grid Overlay]
        SVG[SVG Annotation Layer]
        CANVAS[Canvas Heatmap Overlay]
        API_CLIENT[API Client - api.ts]
    end

    subgraph "Backend (FastAPI - Port 8003)"
        API[REST API - main.py]
        AGENT[Agent Workflow - workflow.py]
        CHAT[Chat Manager - chat.py]
        DB_MOD[Database Module - database.py]
        PROJ[Project Registry - projects.py]
        BATCH[Batch Tasks - batch_tasks.py]
        BEMBED[Batch Embed - batch_embed_tasks.py]
        REPORT[Report Tasks - report_tasks.py]
        PDF[PDF Export - pdf_export.py]
        META[Slide Metadata - slide_metadata.py]
    end

    subgraph "ML Models"
        PF[Path Foundation - 384-dim embeddings]
        MG[MedGemma 4B - Report Generation]
        MS[MedSigLIP - Semantic Search]
        TM[TransMIL x5 - MIL Classification]
        FAISS[FAISS Index - Similarity Search]
        LR[LogisticRegression - Few-Shot Classifier]
    end

    subgraph "Storage"
        PG[(PostgreSQL 16<br/>Schema v5)]
        EMB[/Embeddings .npy<br/>Level 0 + Level 1/]
        WSI_FILES[/WSI Files .svs/]
        MODELS[/Model Checkpoints/]
        HCACHE[/Heatmap Cache .png/]
    end

    UI --> API_CLIENT
    API_CLIENT -->|HTTP/SSE| API
    OSD -->|DZI Tiles| API
    SVG -->|Annotations CRUD| API
    CANVAS -->|Patch Overlay Data| API
    API --> DB_MOD
    API --> AGENT
    API --> CHAT
    API --> BATCH
    API --> BEMBED
    API --> REPORT
    API --> PDF
    AGENT --> MG
    AGENT --> MS
    AGENT --> TM
    AGENT --> FAISS
    API --> PF
    API --> MG
    API --> MS
    API --> TM
    API --> FAISS
    API --> LR
    DB_MOD --> PG
    PROJ --> PG
    PF --> EMB
    TM --> EMB
    API --> WSI_FILES
    TM --> MODELS
    MG --> MODELS
    MS --> MODELS
    API --> HCACHE
```

## 2.2 Component Overview

### Frontend Layer
- **Framework:** Next.js 14 with React 18, TypeScript, Tailwind CSS 3.x
- **WSI Viewer:** OpenSeadragon 4.1 for Deep Zoom Image (DZI) tile-based rendering with SVG annotation overlay, canvas-based patch heatmap overlays, and patch grid overlay
- **Layout:** react-resizable-panels v4 for user-adjustable, collapsible three-panel layout
- **State Management:** React Context (ProjectContext), custom hooks (useAnalysis, useKeyboardShortcuts), localStorage caching
- **API Communication:** Custom fetch wrapper (2,625 lines) with retry logic, timeout handling, SSE streaming, and typed error handling
- **Dark Mode:** Full dark mode support via Tailwind CSS dark variant

### Backend Layer
- **Framework:** FastAPI with Pydantic models for request/response validation
- **Primary Module:** `src/enso_atlas/api/main.py` (6,119 lines) -- houses all core endpoints, model loading, and startup orchestration
- **Database:** asyncpg connection pool to PostgreSQL 16 (raw SQL, no ORM) with schema v5 including annotations table
- **Background Tasks:** Thread-based batch analysis, report generation, and batch re-embedding with status polling and cancellation

### ML Models Layer
- **Path Foundation:** TensorFlow SavedModel producing 384-dim patch embeddings (CPU-only due to Blackwell TF incompatibility)
- **MedGemma 4B:** Transformers-based causal LM for structured report generation (GPU, bfloat16, ~8 GB VRAM)
- **MedSigLIP:** SigLIP vision-language model for text-to-patch semantic search (GPU, fp16, ~800 MB VRAM)
- **TransMIL:** Five PyTorch Transformer-based MIL classifiers with attention extraction (GPU, ~200 MB total)
- **FAISS:** Facebook AI Similarity Search for slide-level (cosine via IndexFlatIP) and patch-level (L2) retrieval
- **scikit-learn:** LogisticRegression for few-shot patch classification on Path Foundation embeddings

### Storage Layer
- **PostgreSQL 16:** Patients, slides, metadata, analysis results, embedding tasks, projects, junction tables, annotations (schema v5)
- **File System:** Pre-computed .npy embeddings (level 0 and level 1), .npy coordinate files, .svs whole-slide images
- **Model Storage:** HuggingFace cache + local checkpoints in `models/` directory
- **Heatmap Cache:** Disk-based PNG cache (`data/embeddings/heatmap_cache/`) for per-model attention heatmaps

## 2.3 Data Flow Diagram

```mermaid
flowchart LR
    subgraph "Offline Pipeline"
        WSI[WSI .svs File] --> PATCH[Patch Extraction<br/>224x224 @ Level 0/1]
        PATCH --> TISSUE[Tissue Masking<br/>Background Removal]
        TISSUE --> PF_EMB[Path Foundation<br/>Embedding]
        PF_EMB --> NPY[.npy Files<br/>N x 384]
    end

    subgraph "Online Analysis"
        NPY --> TRANSMIL[TransMIL x5<br/>Classification]
        TRANSMIL --> PRED[Prediction<br/>+ Attention Weights]
        PRED --> HEATMAP[Attention Heatmap<br/>Per-Model Cached PNG]
        PRED --> EVIDENCE[Top-K Evidence<br/>Patches]
        NPY --> FAISS_Q[FAISS<br/>Query]
        FAISS_Q --> SIMILAR[Similar<br/>Cases]
        NPY --> SIGLIP[MedSigLIP<br/>Semantic Search]
        SIGLIP --> TEXT_MATCH[Text-Matched<br/>Patches]
        NPY --> OUTLIER[Outlier<br/>Detection]
        OUTLIER --> UNUSUAL[Unusual<br/>Patches]
        NPY --> FEWSHOT[Few-Shot<br/>Classifier]
        FEWSHOT --> TISSUE_MAP[Tissue<br/>Classification]
    end

    subgraph "Reporting"
        PRED --> MEDGEMMA[MedGemma 4B<br/>Report Generator]
        EVIDENCE --> MEDGEMMA
        SIMILAR --> MEDGEMMA
        MEDGEMMA --> JSON_REPORT[Structured<br/>JSON Report]
        JSON_REPORT --> PDF_GEN[PDF<br/>Generator]
        PDF_GEN --> PDF_OUT[Tumor Board<br/>PDF]
    end
```

## 2.4 Deployment Topology

```
+-----------------------------------+     +------------------+
|  enso-atlas (Application)         |     |  atlas-db        |
|  - FastAPI Backend (port 8003)    |---->|  PostgreSQL 16   |
|  - Path Foundation (CPU)          |     |  (port 5433)     |
|  - MedGemma 4B (GPU, bfloat16)   |     +------------------+
|  - MedSigLIP (GPU, fp16)         |
|  - TransMIL x5 (GPU)             |
|  - FAISS Index (CPU)             |
+-----------------------------------+
        |
        | Port 8003 (API)
        v
+-----------------------------------+
|  Frontend (Next.js 14)            |
|  - Production Build               |
|  - Port 3002                      |
|  - Proxy /api/* -> :8003          |
+-----------------------------------+
        |
        | (optional)
        v
+-----------------------------------+
|  Tailscale Funnel                 |
|  - Public HTTPS access            |
|  - Zero-config TLS                |
+-----------------------------------+
```

### Port Mappings

| Service | Internal Port | External Port | Purpose |
|---|---|---|---|
| enso-atlas | 8000 | 8003 | FastAPI REST API |
| atlas-db | 5432 | 5433 | PostgreSQL |
| frontend | 3002 | 3002 | Next.js production server |

## 2.5 Network Architecture

The Next.js frontend proxies all API requests to the backend via a rewrite rule configured in `frontend/next.config.mjs`:

```javascript
const nextConfig = {
  async rewrites() {
    return [
      {
        source: '/api/:path*',
        destination: 'http://127.0.0.1:8003/api/:path*',
      },
    ]
  },
};
```

This eliminates CORS issues in production and creates a unified origin for the browser. The backend also configures CORS middleware for direct API access during development.

For public access without opening firewall ports, Tailscale Funnel provides zero-config HTTPS tunneling to the frontend, enabling demonstrations and remote access while maintaining the on-premise security model.

---

# 3. Foundation Models

## 3.1 Path Foundation (Google)

### Overview

Path Foundation is Google's histopathology foundation model, based on a DINOv2-style self-supervised learning architecture trained on millions of pathology images. It produces dense 384-dimensional feature vectors from 224x224 pixel tissue patches. In Enso Atlas, these embeddings serve as the universal tissue representation for:

1. TransMIL slide-level classification (5 models)
2. FAISS similar-case retrieval (slide-mean cosine similarity)
3. Outlier tissue detection (centroid distance analysis)
4. Few-shot patch classification (LogisticRegression on embeddings)
5. Attention heatmap generation (per-model, coverage-aligned)
6. Image-to-image visual search (patch-level L2 FAISS)

### Architecture Specifications

| Parameter | Value |
|---|---|
| Model ID | `google/path-foundation` |
| Architecture | Vision Transformer (DINOv2-based) |
| Input Size | 224 x 224 x 3 (RGB) |
| Output Dimension | 384 |
| Framework | TensorFlow SavedModel |
| Inference Function | `model.signatures["serving_default"]` |
| Preprocessing | Float32, normalize to [0, 1] |

### Patching Strategy

Whole-slide images are divided into non-overlapping 224x224 pixel patches at either level 0 (full resolution, typically 40x) or level 1 (downsampled). The patching process includes tissue masking:

1. **Grid Generation:** Regular grid with step size 224 pixels
2. **Tissue Detection:** Pixels with mean intensity < 245 and standard deviation > 10 are considered tissue (relaxed thresholds for maximum patch coverage)
3. **Batch Embedding:** Tissue patches batched (64 patches per batch) through Path Foundation on CPU
4. **Storage:** Embeddings saved as `{slide_id}.npy` (N x 384) with coordinates saved as `{slide_id}_coords.npy` (N x 2)

For a typical ovarian cancer slide (~80,000 x 40,000 pixels at level 0), this produces between 3,000 and 8,000 tissue patches.

### Performance Benchmarks

| Metric | Value |
|---|---|
| Model Loading Time | ~15 seconds |
| Batch Inference (64 patches, CPU) | ~2.5 seconds |
| Per-Patch Latency (amortized) | ~39 ms |
| Memory Usage (CPU) | ~2 GB |
| Full Slide Embedding (6,000 patches, level 0) | ~4 minutes |
| Embedding Dimension | 384 floats = 1.5 KB per patch |

### TensorFlow on CPU

Path Foundation uses TensorFlow, which does not support NVIDIA Blackwell GPUs (compute capability sm_121). The system runs Path Foundation on CPU, which is acceptable because embeddings are pre-computed offline. On-demand embedding is supported for new slides via background tasks with progress tracking.

## 3.2 MedGemma 4B

### Overview

MedGemma is Google's medical language model, a 4-billion parameter instruction-tuned variant of Gemma optimized for medical text generation. In Enso Atlas, MedGemma generates structured clinical reports from model predictions and evidence patches.

### Architecture Specifications

| Parameter | Value |
|---|---|
| Model ID | `google/medgemma-4b-it` |
| Architecture | Gemma-2 Causal LM |
| Parameters | 4 billion |
| Precision | bfloat16 (GPU) |
| VRAM Usage | ~8 GB |
| Max Input Tokens | 512 |
| Max Output Tokens | 384 |
| Temperature | 0.1 |
| Top-p | 0.9 |

### Inference Pipeline

1. **Model Loading:** Lazy-loaded with thread-safe locking in bfloat16 on GPU
2. **Warmup:** Test inference at startup pre-compiles CUDA kernels (60-120s)
3. **Prompt Engineering:** Compact JSON-first prompt forcing structured output
4. **Generation:** `torch.inference_mode()` with configurable max tokens and time limits via custom `StoppingCriteria`
5. **Non-Blocking:** All inference wrapped in `asyncio.to_thread()` to avoid blocking the event loop
6. **JSON Parsing:** Progressive repair strategies for truncated JSON with regex fallback
7. **Safety Validation:** Every report checked against prohibited phrases (e.g., "start treatment", "prescribe")

### Report Schema

```json
{
  "case_id": "TCGA-04-1331-01A-01-BS1",
  "task": "Platinum treatment response prediction",
  "model_output": {
    "label": "responder",
    "probability": 0.94,
    "calibration_note": "Uncalibrated research model"
  },
  "evidence": [...],
  "limitations": [...],
  "suggested_next_steps": [...],
  "safety_statement": "Research tool only...",
  "decision_support": {...}
}
```

## 3.3 MedSigLIP

### Overview

MedSigLIP is Google's medical vision-language model based on the SigLIP architecture. It enables semantic search over tissue patches using natural language queries -- a capability unique to Enso Atlas among pathology AI platforms.

### Architecture Specifications

| Parameter | Value |
|---|---|
| Model ID | `google/medsiglip-448` (preferred) or `google/siglip-so400m-patch14-384` (fallback) |
| Architecture | SigLIP (dual encoder: vision + text) |
| Vision Input | 448 x 448 (MedSigLIP) or 384 x 384 (SigLIP) |
| Embedding Dimension | 1152 |
| Precision | fp16 (GPU) |
| VRAM Usage | ~800 MB |

### Capabilities

- **Text-to-Patch Search:** Natural language queries matched against patch embeddings via cosine similarity
- **On-the-Fly Embedding:** When cached MedSigLIP embeddings are unavailable, patches are extracted from the WSI and embedded in real-time
- **Image-to-Image Search:** Visual similarity search via FAISS using Path Foundation embeddings across the entire database
- **Predefined Query Sets:** Curated queries for tumor, inflammation, necrosis, stroma, mitosis, and vessels

### VRAM Sharing

MedSigLIP shares GPU with MedGemma. At fp16, SigLIP requires ~800 MB alongside MedGemma's ~8 GB, fitting within typical GPU memory.

---

# 4. TransMIL Architecture

## 4.1 Transformer-Based Multiple Instance Learning

TransMIL extends the MIL paradigm with Transformer self-attention, enabling the model to capture inter-patch relationships and spatial context. Attention signals provide the interpretability critical for clinical adoption.

## 4.2 Architecture Details

```mermaid
graph TD
    INPUT["Patch Embeddings<br/>(N x 384)"] --> FC_IN["Linear Projection<br/>(384 -> 512)"]
    FC_IN --> CLS["Prepend CLS Token<br/>(1 x 512)"]
    CLS --> PPEG["Pyramid Position<br/>Encoding (PPEG)"]
    PPEG --> TRANS1["Transformer Layer 1<br/>(8-head self-attention)"]
    TRANS1 --> TRANS2["Transformer Layer 2<br/>(8-head self-attention)"]
    TRANS2 --> NORM["Layer Norm"]
    NORM --> CLS_OUT["Extract CLS Token"]
    CLS_OUT --> CLASSIFY["Classifier Head<br/>(512 -> 256 -> 1)"]
    CLASSIFY --> SIGMOID["Sigmoid"]
    SIGMOID --> PRED["Prediction<br/>(0-1 probability)"]
    TRANS2 -.->|"Attention Weights"| ATTN["Attention Map<br/>(N weights)"]
```

### Hyperparameters

| Parameter | Value |
|---|---|
| Input Dimension | 384 (Path Foundation) |
| Hidden Dimension | 512 |
| Number of Classes | 1 (binary with sigmoid) |
| Attention Heads | 8 |
| Transformer Layers | 2 |
| Dropout | 0.1 (inference) / 0.25 (training) |
| Total Parameters | ~3.2M |

## 4.3 Multi-Model Inference

Five specialized TransMIL models are trained for different prediction targets:

| Model ID | Display Name | Category | AUC | Training Slides |
|---|---|---|---|---|
| `platinum_sensitivity` | Platinum Sensitivity | Ovarian Cancer | 0.907 | 199 |
| `tumor_grade` | Tumor Grade | General Pathology | 0.752 | 918 |
| `survival_5y` | 5-Year Survival | Ovarian Cancer | 0.697 | 965 |
| `survival_3y` | 3-Year Survival | Ovarian Cancer | 0.645 | 1,106 |
| `survival_1y` | 1-Year Survival | Ovarian Cancer | 0.639 | 1,135 |

Multi-model inference runs all models sequentially on the same embeddings in ~100-250ms (GPU). Results are cached to PostgreSQL's `analysis_results` table for instant retrieval on subsequent views (~0.8ms).

## 4.4 Threshold Optimization

The classification threshold is optimized using the Youden J statistic:

```json
{
  "method": "youden_j",
  "threshold": 0.9229,
  "sensitivity": 0.846,
  "specificity": 0.912,
  "auc": 0.879
}
```

The high threshold (0.9229 vs default 0.5) reflects the class imbalance (139:13) and optimizes for balanced sensitivity/specificity.

## 4.5 Training Pipeline

| Parameter | Value |
|---|---|
| Optimizer | AdamW (lr=2e-4, weight_decay=1e-5) |
| Scheduler | CosineAnnealingLR (T_max=50, eta_min=1e-6) |
| Gradient Accumulation | 4 steps |
| Mixed Precision | AMP (autocast + GradScaler) |
| Gradient Clipping | Max norm 1.0 |
| Early Stopping | Patience 15 epochs |
| Train/Val Split | 80/20, stratified |
| Epochs | 100 maximum |

---

# 5. Backend API Specification

## 5.1 Startup and Initialization

The FastAPI application is created via `create_app()` in `src/enso_atlas/api/main.py` (6,119 lines). Startup orchestrates model loading:

```
1.  MIL Classifier (TransMIL checkpoint)            ~2s
2.  Multi-Model Inference (5 models)                 ~5s
3.  Evidence Generator (FAISS index)                 ~3s
4.  Path Foundation Embedder Init (lazy, CPU)        ~0s
5.  MedGemma Reporter (GPU, bfloat16)               ~30s
6.  MedGemma Warmup (CUDA kernel compilation)        ~60-120s
7.  MedSigLIP Embedder (GPU, fp16)                   ~10s
8.  Clinical Decision Support Engine                  ~0.1s
9.  FAISS Patch Index Build                          ~3s
10. Slide-Mean FAISS Index (cosine similarity)        ~1s
11. Label Loading (CSV parsing)                       ~0.5s
12. PostgreSQL Schema Init + Population               ~5-60s (first run)
13. Project Registry (YAML loading)                   ~0.1s
14. Agent Workflow Initialization                     ~0.1s
15. Chat Manager Initialization                       ~0.1s
```

### Timing Benchmarks (DGX Spark, Blackwell GPU)

| Step | Duration |
|---|---|
| TransMIL Loading (5 checkpoints) | 2.1s |
| MedGemma Loading (4B params, bfloat16) | 28.4s |
| MedGemma Warmup (CUDA kernels) | 62.3s |
| MedSigLIP Loading (SigLIP-so400m, fp16) | 9.7s |
| FAISS Index Build (208 slides, ~1M patches) | 3.2s |
| PostgreSQL Init (schema + population) | 4.8s |
| **Total Startup** | **~120s** |

## 5.2 Complete API Endpoint Reference

### Health and Status

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/health` | Health check (model status, CUDA, slide count, DB, uptime) |
| `GET` | `/api/db/status` | Database connection and population status |
| `POST` | `/api/db/repopulate` | Force re-population from flat files |
| `GET` | `/api/embed/status` | Path Foundation embedder status |
| `GET` | `/api/semantic-search/status` | MedSigLIP model status |
| `GET` | `/api/search/visual/status` | Visual search FAISS index status |

### Slide Management

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/slides` | List all slides (with ?project_id= filtering) |
| `GET` | `/api/slides/search` | Search slides with filtering and pagination |
| `GET` | `/api/slides/{id}/dzi` | DZI XML for OpenSeadragon |
| `GET` | `/api/slides/{id}/dzi_files/{level}/{tile}` | DZI tile image |
| `GET` | `/api/slides/{id}/thumbnail` | Slide thumbnail (disk-cached) |
| `GET` | `/api/slides/{id}/info` | Detailed slide info (dimensions, levels) |
| `GET` | `/api/slides/{id}/patches/{patch_id}` | Patch image (from WSI or placeholder) |
| `GET` | `/api/slides/{id}/qc` | Slide quality control metrics |
| `GET` | `/api/slides/{id}/cached-results` | All cached analysis results per model |
| `GET` | `/api/slides/{id}/embedding-status` | Embedding and analysis cache status |
| `PATCH` | `/api/slides/{id}` | Rename slide (update display_name) |

### Analysis

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/analyze` | Single-slide prediction with evidence |
| `POST` | `/api/analyze-multi` | Multi-model ensemble (5 models, with caching) |
| `POST` | `/api/analyze-uncertainty` | MC Dropout uncertainty quantification |
| `POST` | `/api/analyze-batch` | Synchronous batch analysis |
| `POST` | `/api/analyze-batch/async` | Async batch with model selection, level, force re-embed |
| `GET` | `/api/analyze-batch/status/{task_id}` | Batch progress |
| `POST` | `/api/analyze-batch/cancel/{task_id}` | Cancel running batch |
| `GET` | `/api/analyze-batch/tasks` | List all batch tasks |

### Embedding

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/embed` | Embed base64-encoded patches |
| `POST` | `/api/embed-slide` | On-demand slide embedding (level 0 or 1) |
| `GET` | `/api/embed-slide/status/{task_id}` | Embedding task progress |
| `GET` | `/api/embed-slide/tasks` | List embedding tasks |
| `POST` | `/api/embed-slides/batch` | Batch re-embedding (all or selected slides) |
| `GET` | `/api/embed-slides/batch/status/{id}` | Batch embed progress |
| `POST` | `/api/embed-slides/batch/cancel/{id}` | Cancel batch embed |
| `GET` | `/api/embed-slides/batch/active` | Currently active batch embed |

### Search and Retrieval

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/similar` | Similar case search (slide-mean cosine FAISS) |
| `POST` | `/api/semantic-search` | MedSigLIP text-to-patch search |
| `POST` | `/api/search/visual` | Image-to-image FAISS search |
| `POST` | `/api/classify-region` | Tissue type classification at coordinates |

### Heatmaps

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/heatmap/{slide_id}` | Default attention heatmap (configurable level, smooth, blur) |
| `GET` | `/api/heatmap/{slide_id}/{model_id}` | Per-model heatmap (disk-cached PNG, coverage-aligned) |

### Outlier Detection and Few-Shot Classification

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/slides/{id}/outlier-detection` | Detect outlier patches (centroid distance) |
| `POST` | `/api/slides/{id}/patch-classify` | Few-shot classification (LogisticRegression) |
| `GET` | `/api/slides/{id}/patch-coords` | Patch coordinates for spatial selection |

### Annotations

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/slides/{id}/annotations` | List all annotations for a slide |
| `POST` | `/api/slides/{id}/annotations` | Create annotation |
| `PUT` | `/api/slides/{id}/annotations/{ann_id}` | Update annotation |
| `DELETE` | `/api/slides/{id}/annotations/{ann_id}` | Delete annotation |
| `GET` | `/api/slides/{id}/annotations/summary` | Annotation summary by label |

### Reports and Export

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/report` | Generate MedGemma report (sync) |
| `POST` | `/api/report/async` | Async report generation |
| `GET` | `/api/report/status/{task_id}` | Report generation status |
| `GET` | `/api/report/tasks` | List report tasks |
| `POST` | `/api/report/pdf` | Generate PDF from report JSON (fpdf2) |
| `POST` | `/api/export/pdf` | Full PDF export with heatmap (reportlab) |

### Projects

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/projects` | List all projects |
| `POST` | `/api/projects` | Create project |
| `GET` | `/api/projects/{id}` | Get project details |
| `PUT` | `/api/projects/{id}` | Update project |
| `DELETE` | `/api/projects/{id}` | Delete project |
| `GET` | `/api/projects/{id}/slides` | List project slides |
| `POST` | `/api/projects/{id}/slides` | Assign slides |
| `DELETE` | `/api/projects/{id}/slides` | Unassign slides |
| `GET` | `/api/projects/{id}/models` | List project models |
| `POST` | `/api/projects/{id}/models` | Assign models |
| `DELETE` | `/api/projects/{id}/models` | Unassign models |
| `POST` | `/api/projects/{id}/upload` | Upload slide file |
| `GET` | `/api/projects/{id}/status` | Project readiness status |
| `GET` | `/api/models` | List available models (with ?project_id= filtering) |

### Agent Workflow

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/agent/analyze` | Start 7-step agent analysis (SSE) |
| `POST` | `/api/agent/followup` | Follow-up questions (SSE) |
| `GET` | `/api/agent/session/{id}` | Get session details |
| `GET` | `/api/agent/sessions` | List active sessions |
| `DELETE` | `/api/agent/session/{id}` | Delete session |

### Chat

| Method | Path | Description |
|---|---|---|
| `POST` | `/api/chat` | RAG-based conversational AI (SSE) |
| `GET` | `/api/chat/session/{id}` | Get chat session history |

### History and Audit

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/history` | Analysis history with filtering |
| `GET` | `/api/slides/{id}/history` | Per-slide history |
| `GET` | `/api/audit-log` | Compliance audit trail |

### Tags and Groups (Stubs)

| Method | Path | Description |
|---|---|---|
| `GET` | `/api/tags` | List tags |
| `POST` | `/api/tags` | Create tag |
| `GET` | `/api/groups` | List groups |
| `POST` | `/api/groups` | Create group |

---

# 6. Agentic Workflow

## 6.1 Overview

The agentic workflow implements a seven-step AI pipeline that performs comprehensive slide analysis with visible reasoning, retrieval-augmented generation, and structured report production.

### Design Principles

1. **Transparency:** Every step produces visible reasoning the clinician can inspect
2. **Streaming:** Results streamed via Server-Sent Events (SSE) for real-time progress
3. **Session Memory:** Sessions persist analysis state for follow-up questions
4. **Graceful Degradation:** Each step can be skipped if dependencies are unavailable

## 6.2 Seven-Step Pipeline

```mermaid
sequenceDiagram
    participant Client
    participant API
    participant Agent
    participant TransMIL
    participant FAISS
    participant MedSigLIP
    participant MedGemma

    Client->>API: POST /api/agent/analyze
    API->>Agent: run_workflow()

    Note over Agent: Step 1: INITIALIZE
    Agent->>Agent: Load embeddings + coordinates
    Agent-->>Client: SSE: initialize complete (~50ms)

    Note over Agent: Step 2: ANALYZE
    Agent->>TransMIL: predict_all(embeddings)
    TransMIL-->>Agent: predictions + attention
    Agent-->>Client: SSE: analyze complete (~200ms)

    Note over Agent: Step 3: RETRIEVE
    Agent->>FAISS: search(mean_embedding, k=10)
    FAISS-->>Agent: similar cases
    Agent-->>Client: SSE: retrieve complete (~10ms)

    Note over Agent: Step 4: SEMANTIC SEARCH
    Agent->>MedSigLIP: search(queries, embeddings)
    MedSigLIP-->>Agent: tissue pattern matches
    Agent-->>Client: SSE: semantic_search complete (~100ms)

    Note over Agent: Step 5: COMPARE
    Agent->>Agent: Analyze similar case patterns
    Agent-->>Client: SSE: compare complete (~5ms)

    Note over Agent: Step 6: REASON
    Agent->>Agent: Synthesize evidence
    Agent-->>Client: SSE: reason complete (~10ms)

    Note over Agent: Step 7: REPORT
    Agent->>MedGemma: generate_report()
    MedGemma-->>Agent: structured report
    Agent-->>Client: SSE: report complete (10-120s)
```

## 6.3 SSE Streaming Format

```json
{
  "step": "analyze",
  "status": "complete",
  "message": "Ran 5 models on 6,234 patches",
  "reasoning": "Model predictions:\n- Platinum Sensitivity: sensitive (score: 0.94)...",
  "data": {"predictions": {}, "top_evidence": []},
  "timestamp": "2025-02-06T23:57:42.123Z",
  "duration_ms": 187.3
}
```

## 6.4 Session Management

Sessions are stored in-memory with the `AgentState` dataclass, enabling follow-up questions that reference previous analysis results without re-running the full workflow.

---

# 7. Database Schema

## 7.1 Schema Version 5

The database schema (defined in `src/enso_atlas/api/database.py`) consists of ten tables across five migration versions:

### ER Diagram

```mermaid
erDiagram
    patients ||--o{ slides : "has"
    slides ||--o{ slide_metadata : "has"
    slides ||--o{ analysis_results : "has"
    slides ||--o{ embedding_tasks : "has"
    slides ||--o{ annotations : "has"
    projects ||--o{ project_slides : "has"
    slides ||--o{ project_slides : "assigned to"
    projects ||--o{ project_models : "has"

    patients {
        text patient_id PK
        integer age
        text sex
        text stage
        text grade
        integer prior_lines
        text histology
        text treatment_response
        text diagnosis
        text vital_status
        timestamptz created_at
        timestamptz updated_at
    }

    slides {
        text slide_id PK
        text patient_id FK
        text display_name
        text filename
        integer width
        integer height
        float mpp
        text magnification
        integer num_patches
        boolean has_embeddings
        boolean has_level0_embeddings
        text label
        text project_id
        timestamptz embedding_date
        text file_path
        bigint file_size_bytes
        timestamptz created_at
        timestamptz updated_at
    }

    slide_metadata {
        bigserial id PK
        text slide_id FK
        text key
        text value
        timestamptz created_at
        timestamptz updated_at
    }

    analysis_results {
        bigserial id PK
        text slide_id FK
        text model_id
        float score
        text label
        float confidence
        float threshold
        text attention_hash
        timestamptz created_at
    }

    embedding_tasks {
        text task_id PK
        text slide_id FK
        integer level
        text status
        float progress
        timestamptz created_at
        timestamptz completed_at
        text error
    }

    projects {
        text id PK
        text name
        text cancer_type
        text prediction_target
        jsonb config_json
        timestamptz created_at
        timestamptz updated_at
    }

    project_slides {
        text project_id PK_FK
        text slide_id PK_FK
        timestamptz created_at
    }

    project_models {
        text project_id PK_FK
        text model_id PK
        timestamptz created_at
    }

    annotations {
        text id PK
        text slide_id
        text type
        jsonb coordinates
        text label
        text notes
        text color
        text category
        timestamptz created_at
        timestamptz updated_at
    }

    schema_version {
        integer version PK
        timestamptz applied_at
    }
```

## 7.2 Migration History

| Version | Migration | Description |
|---|---|---|
| v1 | Initial schema | patients, slides, slide_metadata, analysis_results, embedding_tasks, projects, schema_version |
| v2 | `_migrate_project_columns` | Added `project_id` column to slides table |
| v3 | `_migrate_project_scoped_tables` | Created project_models and project_slides junction tables, seeded initial data |
| v4 | `_migrate_display_name` | Added `display_name` column to slides table for user-assigned aliases |
| v5 | `_migrate_annotations_table` | Created annotations table with JSONB coordinates, label, notes, color, category |

## 7.3 Connection Pool

```python
_pool = await asyncpg.create_pool(
    DATABASE_URL,
    min_size=2,
    max_size=10,
    command_timeout=60,
)
```

10 retry attempts with 2-second delay for database startup synchronization.

## 7.4 Query Performance

| Query | PostgreSQL | Flat-File Fallback |
|---|---|---|
| List all slides (208) | 2-5ms | 30-60s |
| Get single slide | <1ms | N/A |
| Search with filters | 5-10ms | 100-500ms |
| Cached result lookup | 0.8ms | N/A |
| Annotations for slide | <2ms | N/A |
| Count slides | <1ms | N/A |

---

# 8. Frontend Architecture

## 8.1 Tech Stack

| Technology | Version | Purpose |
|---|---|---|
| Next.js | 14.2 | React framework with SSR, routing, API proxying |
| React | 18 | UI component library |
| TypeScript | 5.x | Type-safe frontend development |
| Tailwind CSS | 3.x | Utility-first CSS with dark mode support |
| OpenSeadragon | 4.1 | Tile-based whole-slide image viewer |
| react-resizable-panels | 4.x | Resizable and collapsible layout panels |
| Lucide React | - | Icon library |

## 8.2 Component Hierarchy

```
App (layout.tsx)
  +-- ProjectProvider (ProjectContext.tsx)
      +-- HomePage (page.tsx, 2142 lines)
          +-- Header
          |   +-- ProjectSwitcher
          |   +-- ViewModeToggle (oncologist/pathologist)
          |   +-- DemoModeToggle
          |   +-- Dark Mode Toggle
          +-- PanelGroup (react-resizable-panels)
              +-- Left Panel (collapsible)
              |   +-- SlideSelector (25,527 bytes)
              |   +-- QuickStatsPanel
              |   +-- AnalysisControls
              +-- Center Panel
              |   +-- WSIViewer (61,161 bytes)
              |   |   +-- OpenSeadragon Canvas
              |   |   +-- SVG Annotation Overlay
              |   |   +-- Canvas Patch Overlay (outlier/classifier heatmaps)
              |   |   +-- Patch Grid Overlay (224px boundaries)
              |   |   +-- Real-Time Scale Bar
              |   |   +-- Navigator Minimap
              |   |   +-- Heatmap Model Selector
              +-- Right Panel (collapsible)
              |   +-- PredictionPanel
              |   +-- MultiModelPredictionPanel
              |   +-- EvidencePanel
              |   +-- SimilarCasesPanel
              |   +-- SemanticSearchPanel
              |   +-- ReportPanel
              |   +-- BatchAnalysisPanel (43,366 bytes)
              |   +-- AIAssistantPanel (38,056 bytes)
              |   +-- OutlierDetectorPanel (11,988 bytes)
              |   +-- PatchClassifierPanel (16,135 bytes)
              |   +-- CaseNotesPanel
              |   +-- UncertaintyPanel
              +-- Footer
              +-- Modals
                  +-- PatchZoomModal
                  +-- KeyboardShortcutsModal
                  +-- SettingsModal
                  +-- SystemStatusModal
                  +-- WelcomeModal

Slides Page (/slides/page.tsx)
  +-- SlideManager
      +-- GridView / TableView (with thumbnails)
      +-- FilterPanel (label, embeddings, patches, date, search)
      +-- BulkActions
      +-- Pagination

Projects Page (/projects/page.tsx)
  +-- ProjectManager
      +-- ProjectList (CRUD cards with readiness status)
      +-- SlideUpload
      +-- ModelAssignment
      +-- SlideAssignment
```

## 8.3 WSI Viewer (61,161 bytes)

The WSI viewer (`frontend/src/components/viewer/WSIViewer.tsx`) is the central component:

### Features

- **OpenSeadragon Integration:** DZI tile-based rendering with navigator minimap, double-click zoom, scroll zoom
- **Attention Heatmap Overlay:** Per-model heatmaps loaded as OSD `addSimpleImage` overlays with configurable opacity and model selection dropdown
- **Canvas-Based Patch Overlay:** Separate HTML canvas for outlier detection and few-shot classifier heatmaps, rendered independently from OSD heatmaps
- **Patch Grid Overlay:** 224px boundary grid drawn on a dedicated canvas with configurable opacity and color (cyan default), toggled via toolbar
- **SVG Annotation Layer:** Real-time drawing of circle, rectangle, freehand, and point annotations using SVG overlay positioned in OSD viewport coordinates
- **Spatial Patch Selection:** Click-to-select mode for few-shot classifier -- clicking on the viewer identifies the nearest patch and adds it to the active class
- **Real-Time Scale Bar:** Imperative DOM updates (bypassing React render) on every OSD animation frame for smooth magnification and scale display
- **Canvas2D Optimization:** Patches HTMLCanvasElement.getContext to add `willReadFrequently: true` for OpenSeadragon pixel data access

### Scale Bar Implementation

The scale bar uses direct DOM manipulation for zero-latency updates:

```typescript
const updateScaleDisplay = useCallback((z: number) => {
    const info = computeScaleBar(z);
    if (scaleTextRef.current) {
        scaleTextRef.current.textContent = `${info.displayValue} ${info.displayUnit}`;
    }
    if (magTextRef.current) {
        magTextRef.current.textContent = `${info.effectiveMag.toFixed(1)}x`;
    }
}, [computeScaleBar]);
```

This avoids React re-renders during continuous zoom/pan operations.

## 8.4 Resizable Panels

All major layout panels use react-resizable-panels v4:

- **Three-panel layout:** Left sidebar (slide selector), center (WSI viewer), right sidebar (analysis results)
- **Collapsible:** Each sidebar can be collapsed via toggle buttons with smooth animation
- **Persistent:** Panel sizes are remembered across sessions
- **Responsive:** Mobile view switches to tabbed panels (Slides / Results)

## 8.5 Dark Mode

Full dark mode support via Tailwind CSS `dark:` variant:

- Toggle in the header persisted to localStorage
- All components styled with dark variants (slate-800, slate-700, etc.)
- OpenSeadragon navigator styled with dark background
- Charts and visualizations adapt to dark theme

## 8.6 State Management

### ProjectContext

Global project configuration providing `currentProject` and `switchProject()`. Selected project persisted to localStorage.

### useAnalysis Hook

Manages analysis state (loading, results, error) with retry support.

### Key State Variables in page.tsx

- `outlierHeatmapData` / `showOutlierHeatmap`: Canvas-based outlier visualization
- `classifyResult` / `showClassifyHeatmap`: Canvas-based classifier visualization
- `patchSelectionMode` / `patchCoordinates`: Spatial selection for few-shot classifier
- `annotations` / `activeAnnotationTool`: Pathologist annotation state
- `multiModelResult` / `selectedModels`: Multi-model analysis
- `resolutionLevel` / `forceReembed`: Batch analysis configuration
- `heatmapModel` / `heatmapLevel`: Per-model heatmap selection

## 8.7 API Client (2,625 lines)

The API client (`frontend/src/lib/api.ts`) implements:

- **Retry Logic:** 3 retries with exponential backoff for 408, 429, 500, 502, 503, 504
- **Typed Errors:** `AtlasApiError` with `getUserMessage()` for display
- **SSE Streaming:** AsyncGenerator for agent and chat endpoints
- **Functions:** `detectOutliers()`, `classifyPatches()`, `getPatchCoords()`, `getAnnotations()`, `saveAnnotation()`, `deleteAnnotation()`, `getSlideCachedResults()`, `embedSlideWithPolling()`, `analyzeSlideMultiModel()`, `visualSearch()`, plus all standard CRUD operations

---

# 9. Config-Driven Project System

## 9.1 YAML Schema

Projects are defined in `config/projects.yaml`:

```yaml
foundation_models:
  path_foundation:
    name: "Path Foundation"
    embedding_dim: 384
    description: "Google Health pathology foundation model (ViT-S, 384-dim)"
  dinov2:
    name: "DINOv2"
    embedding_dim: 768
  uni:
    name: "UNI"
    embedding_dim: 1024
  conch:
    name: "CONCH"
    embedding_dim: 512

classification_models:
  platinum_sensitivity:
    model_dir: "transmil_v2"
    display_name: "Platinum Sensitivity"
    auc: 0.907
    n_slides: 199
    category: "ovarian_cancer"
    positive_label: "Sensitive"
    negative_label: "Resistant"
    compatible_foundation: "path_foundation"
  # ... (5 models total)

projects:
  ovarian-platinum:
    name: "Ovarian Cancer - Platinum Sensitivity"
    cancer_type: Ovarian Cancer
    prediction_target: platinum_sensitivity
    classes: ["resistant", "sensitive"]
    positive_class: sensitive
    foundation_model: path_foundation
    classification_models:
      - platinum_sensitivity
      - tumor_grade
      - survival_5y
      - survival_3y
      - survival_1y
    features:
      medgemma_reports: true
      medsiglip_search: true
    threshold: 0.9229
```

## 9.2 ProjectRegistry Backend

The `ProjectRegistry` class loads and manages project configurations with PostgreSQL synchronization on startup. Junction tables (`project_slides`, `project_models`) provide many-to-many relationships.

## 9.3 Adding a New Cancer Type

1. Add project definition to `config/projects.yaml`
2. Prepare training data in dataset directories
3. Run embedding pipeline: `python scripts/embed_level0_pipelined.py`
4. Train TransMIL model: `python scripts/train_transmil.py`
5. Restart server -- project auto-loads in frontend switcher

---

# 10. Outlier Detection and Few-Shot Classification

## 10.1 Outlier Tissue Detector

The outlier detector identifies morphologically unusual tissue patches by measuring each patch's distance from the embedding centroid.

### Algorithm

```
1. Load Path Foundation embeddings (N x 384) for the slide
2. Compute centroid = mean(embeddings, axis=0)
3. Compute distances = ||embedding_i - centroid||_2 for all patches
4. Compute mean_dist, std_dist
5. Flag patches where distance > mean_dist + threshold * std_dist
6. Normalize all distances to [0, 1] for heatmap rendering
7. Return outlier patches sorted by distance (descending)
```

### API

```
POST /api/slides/{slide_id}/outlier-detection?threshold=2.0
```

**Response:** `OutlierDetectionResponse` with:
- `outlier_patches`: List of outlier patches with (x, y, distance, z_score)
- `heatmap_data`: All patches with normalized scores for canvas overlay
- Statistics: `mean_distance`, `std_distance`, `outlier_count`, `total_patches`

### Frontend Integration

The `OutlierDetectorPanel` component:
- Configurable z-score threshold (default 2.0)
- Toggle heatmap overlay on/off (renders on dedicated canvas, not OSD)
- Click outlier patches to navigate WSI viewer to that location
- Shows top outliers with z-scores and coordinates

## 10.2 Few-Shot Patch Classifier

The few-shot classifier enables pathologists to define custom tissue classes by selecting example patches, then classifies all patches in the slide.

### Algorithm

```
1. User defines 2+ classes with example patch indices
   (via text input "1,2,3,10-20" or spatial click selection on viewer)
2. Load Path Foundation embeddings for example patches
3. Train LogisticRegression(max_iter=1000) on example embeddings
4. Predict all N patches in the slide
5. Compute per-class probabilities
6. Leave-one-out cross-validation for accuracy estimate
7. Return per-patch predictions with confidence and class heatmap data
```

### API

```
POST /api/slides/{slide_id}/patch-classify
{
  "classes": {
    "tumor": [10, 42, 103, 255],
    "stroma": [5, 88, 190, 301]
  }
}
```

**Response:** `PatchClassifyResponse` with:
- `predictions`: Per-patch (patch_idx, x, y, predicted_class, confidence, probabilities)
- `class_counts`: Distribution across classes
- `accuracy_estimate`: Leave-one-out accuracy on training examples
- `heatmap_data`: Per-patch (x, y, class_idx, confidence) for canvas overlay

### Spatial Selection Mode

The frontend supports click-to-select on the WSI viewer:

1. User creates class names in PatchClassifierPanel
2. Clicks "Select on Map" for a class -- enters spatial selection mode
3. Clicks on the WSI viewer -- nearest patch (by coordinate) is added to the class
4. Patch coordinates are loaded via `GET /api/slides/{id}/patch-coords`
5. Selected patches highlighted with class-specific colors on the viewer

### Frontend Integration

The `PatchClassifierPanel` component:
- Add/remove classes with auto-assigned colors (8 predefined colors)
- Input patch indices via text or spatial selection
- Parse ranges (e.g., "10-20")
- Run classification and display class distribution
- Toggle class heatmap overlay (canvas-based, separate from OSD heatmap)

---

# 11. Annotation System

## 11.1 Overview

The annotation system provides pathologist-grade markup tools for WSI review, persisted to PostgreSQL for multi-session access.

## 11.2 Annotation Types

| Type | Drawing Method | Coordinates |
|---|---|---|
| Circle | Click + drag | {x, y, width, height} |
| Rectangle | Click + drag | {x, y, width, height} |
| Freehand | Click + draw path | {x, y, width, height, points: [{x, y}]} |
| Point | Single click | {x, y, width: 0, height: 0} |

## 11.3 SVG Rendering

Annotations are rendered as an SVG overlay positioned in OpenSeadragon viewport coordinates:

- Drawing preview updates in real-time as the user drags
- Completed annotations are stored with image-space coordinates
- SVG elements are styled with the annotation's color property
- Selected annotations are highlighted with a distinct border
- Annotations remain correctly positioned during zoom/pan

## 11.4 PostgreSQL Persistence

```sql
CREATE TABLE annotations (
    id TEXT PRIMARY KEY,           -- "ann_{uuid12}"
    slide_id TEXT NOT NULL,
    type TEXT NOT NULL,            -- circle, rectangle, freehand, point
    coordinates JSONB NOT NULL,    -- {x, y, width, height, points?}
    label TEXT,
    notes TEXT,
    color TEXT DEFAULT '#3b82f6',
    category TEXT,                 -- mitotic, tumor, stroma, etc.
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);
```

## 11.5 API

Full CRUD operations:
- `GET /api/slides/{id}/annotations` -- List all annotations
- `POST /api/slides/{id}/annotations` -- Create (auto-generates ID)
- `PUT /api/slides/{id}/annotations/{ann_id}` -- Update label/notes/color/category
- `DELETE /api/slides/{id}/annotations/{ann_id}` -- Delete
- `GET /api/slides/{id}/annotations/summary` -- Count by label

All annotation operations are logged to the audit trail.

---

# 12. Heatmap and Overlay System

## 12.1 Attention Heatmaps (OSD Layer)

Attention heatmaps are generated from TransMIL attention weights and rendered as OpenSeadragon overlays:

### Per-Model Heatmaps

Each of the 5 TransMIL models produces its own attention heatmap:
- Endpoint: `GET /api/heatmap/{slide_id}/{model_id}`
- Format: PNG with RGBA (transparent background)
- Resolution: 1 pixel per 224px patch (grid_w x grid_h)
- Alignment: Coverage-based -- `ceil(slide_dim / 224) * 224` ensures the heatmap covers exactly the patch grid area

### Coverage-Based Alignment

The heatmap dimensions are computed to match the coverage area of 224px patches:

```python
grid_w = int(np.ceil(slide_w / patch_size))
grid_h = int(np.ceil(slide_h / patch_size))
```

Response headers include both slide dimensions and coverage dimensions:
```
X-Slide-Width: 80000
X-Slide-Height: 40000
X-Coverage-Width: 80136    # grid_w * 224
X-Coverage-Height: 40096   # grid_h * 224
```

The frontend uses coverage dimensions for positioning the heatmap overlay to ensure pixel-perfect alignment with patch boundaries.

### Disk-Based Caching

Heatmaps are cached to `data/embeddings/heatmap_cache/{slide_id}_{model_id}.png` after first generation. Subsequent requests serve the cached file directly via `FileResponse`.

### Configurable Rendering

The default (non-model-specific) heatmap endpoint supports:
- `level`: 0=2048px, 1=1024px, 2=512px (default), 3=256px, 4=128px
- `smooth`: Gaussian blur (default true)
- `blur`: Kernel size (default 31, odd number)

## 12.2 Canvas-Based Patch Overlays

Outlier detection and few-shot classification produce per-patch data that is rendered on a separate HTML canvas overlaid on the viewer, independent of the OSD heatmap system:

### Outlier Heatmap
- Data: Array of {x, y, score} where score is normalized distance [0, 1]
- Only outlier patches are highlighted (filtered by z-score threshold)
- Color: Warm palette (yellow to red) based on score

### Classifier Heatmap
- Data: Array of {x, y, class_idx, confidence}
- Each class assigned a distinct color from 8 predefined colors
- Opacity modulated by confidence

### PatchOverlay Type
```typescript
interface PatchOverlay {
    data: Array<{ x: number; y: number; score?: number; class_idx?: number; confidence?: number }>;
    type: "outlier" | "classifier";
    classColors?: string[];
}
```

## 12.3 Patch Grid Overlay

A dedicated canvas renders 224px patch boundaries:
- Toggle via toolbar button (Grid icon)
- Configurable opacity (0-1 range via slider)
- Configurable color (default cyan #00ffff)
- Lines drawn at every 224px interval aligned to the patch extraction grid
- Helps pathologists understand which regions map to which patches

---

# 13. Deployment Guide

## 13.1 Docker Compose Configuration

```yaml
services:
  enso-atlas:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: enso-atlas
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      MIL_ARCHITECTURE: transmil
      MIL_THRESHOLD_CONFIG: /app/models/threshold_config.json
      DATABASE_URL: "postgresql://enso:enso_atlas_2024@atlas-db:5432/enso_atlas"
      TRANSFORMERS_OFFLINE: "${TRANSFORMERS_OFFLINE:-0}"
      HF_HUB_OFFLINE: "${HF_HUB_OFFLINE:-0}"
    volumes:
      - ~/med-gemma-hackathon/data:/app/data
      - ~/med-gemma-hackathon/outputs:/app/outputs
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ~/med-gemma-hackathon/models:/app/models
      - ~/med-gemma-hackathon/config:/app/config
      - ~/med-gemma-hackathon/src:/app/src:ro
    ports:
      - "8003:8000"
    depends_on:
      atlas-db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  atlas-db:
    image: postgres:16
    container_name: atlas-db
    environment:
      POSTGRES_DB: enso_atlas
      POSTGRES_USER: enso
      POSTGRES_PASSWORD: enso_atlas_2024
    volumes:
      - atlas-pgdata:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U enso -d enso_atlas"]
      interval: 5s
      timeout: 3s
      retries: 10
```

## 13.2 DGX Spark Specifics

| Specification | Value |
|---|---|
| GPU | NVIDIA Blackwell (compute capability sm_121) |
| Architecture | ARM64 (aarch64) |
| VRAM | 128 GB |
| RAM | 128 GB |
| Base Image | `nvcr.io/nvidia/pytorch:24.04-py3` |
| Known Issue | TensorFlow does not support sm_121 -- Path Foundation runs on CPU |

## 13.3 Frontend Deployment

```bash
cd frontend
npm install
npm run build
npx next start -p 3002
```

The Next.js production build proxies `/api/*` to the backend.

## 13.4 Tailscale Funnel (Public Access)

For demonstrations and remote access without opening firewall ports:

```bash
tailscale funnel 3002
```

Provides public HTTPS access to the frontend at `https://<hostname>.ts.net/` with automatic TLS certificate management. The backend remains accessible only within the Tailscale network.

## 13.5 Health Check Verification

```bash
# Backend health check
curl http://localhost:8003/api/health
# Expected: {"status": "healthy", "model_loaded": true, "slides_available": 208, "db_available": true}

# Database status
curl http://localhost:8003/api/db/status
# Expected: {"status": "connected", "slides": 208, "patients": 98}
```

## 13.6 Hospital Deployment Walkthrough

This section provides a step-by-step guide for hospital IT teams to deploy Enso Atlas on their own infrastructure with their own data and models.

### Step 1: Hardware Selection

| Configuration | RAM | GPU | Use Case |
|---|---|---|---|
| Mac mini M2/M4 (minimum) | 16 GB | Integrated (MPS) | Small cohorts (<500 slides), CPU embedding |
| Mac mini M4 Pro/Max | 32-64 GB | Integrated (MPS) | Medium cohorts, faster MedGemma inference |
| Linux workstation + A40/L40 | 32+ GB + 48 GB VRAM | NVIDIA CUDA | Full performance, GPU embedding |
| NVIDIA DGX Spark | 128 GB unified | Blackwell (limited TF support) | Reference deployment |

### Step 2: Install and Start

```bash
git clone https://github.com/Hilo-Hilo/med-gemma-hackathon.git
cd med-gemma-hackathon/docker
docker compose up -d
```

Wait approximately 3-4 minutes for model loading and warmup. Verify with:

```bash
curl http://localhost:8003/api/health
```

### Step 3: Add Your Own Cancer Type

Edit `config/projects.yaml` to add a new project. Example for lung adenocarcinoma:

```yaml
foundation_models:
  path_foundation:
    name: "Path Foundation"
    embedding_dim: 384
    description: "Google Health pathology foundation model"
  # Add your own foundation model:
  uni_v2:
    name: "UNI v2"
    embedding_dim: 1024
    description: "Mass General Brigham universal pathology encoder"

classification_models:
  # Add your trained model:
  egfr_mutation:
    model_dir: "egfr_transmil_v1"
    display_name: "EGFR Mutation Prediction"
    auc: 0.83
    n_slides: 450
    category: "lung_cancer"
    positive_label: "EGFR Mutant"
    negative_label: "Wild Type"
    compatible_foundation: "path_foundation"
    embedding_dim: 384

projects:
  # Keep existing demo project:
  ovarian-platinum:
    # ... (unchanged)

  # Add your new project:
  lung-egfr:
    name: "Lung Adenocarcinoma - EGFR Mutation"
    cancer_type: "Lung Cancer"
    prediction_target: egfr_mutation
    classes: ["wild_type", "mutant"]
    positive_class: mutant
    foundation_model: path_foundation
    classification_models:
      - egfr_mutation
    features:
      medgemma_reports: true
      medsiglip_search: false    # Disable if not needed
      semantic_search: false
    threshold: 0.5               # Adjust after validation
```

### Step 4: Train a Classification Model

```bash
# 1. Place WSI files in a slides directory
mkdir -p /data/lung_slides

# 2. Extract patches and generate embeddings
python scripts/embed_level0_pipelined.py \
  --slides-dir /data/lung_slides \
  --output-dir /data/lung_embeddings \
  --batch-size 512 --threads 32

# 3. Prepare labels CSV (slide_id, label columns)
# Format: slide_id,egfr_status
# Example: TCGA-XX-XXXX.svs,mutant

# 4. Train TransMIL
python scripts/train_transmil.py \
  --embeddings-dir /data/lung_embeddings \
  --labels /data/lung_labels.csv \
  --output-dir models/egfr_transmil_v1 \
  --target-column egfr_status \
  --positive-class mutant

# 5. Copy weights to the models directory
cp models/egfr_transmil_v1/best_model.pt models/egfr_transmil_v1/

# 6. Restart the server
cd docker && docker compose restart enso-atlas
```

### Step 5: Swap Foundation Models

To use a different foundation model (e.g., UNI instead of Path Foundation):

1. Register the model in `foundation_models` section of `projects.yaml` with the correct `embedding_dim`
2. Implement the embedding interface in `src/enso_atlas/embeddings/` (a function that takes image patches and returns vectors)
3. Update the project's `foundation_model` field to reference the new model
4. Re-embed slides using the new model (existing embeddings are model-specific)
5. Re-train classification heads on the new embeddings (embedding dimensions must match)

The classification models specify `compatible_foundation` and `embedding_dim` to prevent mismatched embeddings from being used.

### Step 6: Configure Feature Toggles

Each project independently controls which features are available:

```yaml
features:
  medgemma_reports: true    # AI-generated clinical reports (requires MedGemma)
  medsiglip_search: true    # Semantic text-to-patch search (requires MedSigLIP)
  semantic_search: true     # Similar case retrieval (requires FAISS index)
```

Set any feature to `false` to disable it for a specific project. This is useful when:
- MedGemma or MedSigLIP are not installed (e.g., CPU-only deployment)
- Certain features are not relevant for the cancer type
- You want a simplified interface for specific user groups

### Step 7: Network and Security

- **Air-gapped deployment:** The system runs entirely on-premise. No external API calls are made during inference.
- **Tailscale (optional):** For secure remote access without opening firewall ports: `tailscale funnel 3002`
- **Reverse proxy:** Place behind nginx or Caddy for TLS termination and authentication integration with hospital SSO (SAML, LDAP)
- **Database backups:** PostgreSQL data in Docker volume. Schedule `pg_dump` via cron for backup.

```bash
# Backup database
docker exec atlas-db pg_dump -U postgres enso_atlas > backup_$(date +%Y%m%d).sql

# Restore
cat backup_20260210.sql | docker exec -i atlas-db psql -U postgres enso_atlas
```

---

# 14. Data Pipeline

## 14.1 TCGA Data

Training data: 208 TCGA ovarian cancer whole-slide images with platinum sensitivity labels, survival data, and demographics.

## 14.2 Patch Extraction

The pipelined extraction script (`scripts/embed_level0_pipelined.py`) uses producer/consumer:

```
CPU Thread                  GPU Thread
(extract patches,    --->   (Path Foundation embed,
 tissue mask,                save .npy files)
 batch to queue)
```

### Tissue Masking

```python
# Relaxed thresholds for maximum tissue coverage
if mean_val < 245 and std_val > 10:
    patches.append(patch_array)
```

### Output Files

- `{slide_id}.npy` -- Embedding array (N x 384)
- `{slide_id}_coords.npy` -- Coordinate array (N x 2) with (x, y) at level 0

## 14.3 Multi-Level Embeddings

| Level | Resolution | Typical Patches | Use Case |
|---|---|---|---|
| Level 0 | Full resolution (40x) | 3,000-8,000 | Production analysis |
| Level 1 | Downsampled | 100-500 | Quick preview, development |

The batch analysis panel allows users to select embedding level and force re-embedding.

---

# 15. Security and Compliance

## 15.1 On-Premise Design

No data leaves the hospital network:

- **No cloud dependencies at runtime:** `TRANSFORMERS_OFFLINE=1` and `HF_HUB_OFFLINE=1` enforce air-gapped operation
- **No telemetry:** All analytics disabled
- **Local database:** PostgreSQL co-located Docker container
- **Local storage:** All embeddings, slides, and model weights on local volumes

```
+-------------------------------------------------------+
|  Hospital Network (Air-Gapped)                        |
|                                                       |
|  +-------------------+    +----------------------+    |
|  |  PACS / LIS       |--->|  Enso Atlas Server  |    |
|  |  (Slide Export)    |    |  - API (8003)       |    |
|  +-------------------+    |  - DB (5433)         |    |
|                           |  - Frontend (3002)   |    |
|                           +----------------------+    |
|                                    |                  |
|                           +--------v--------+         |
|                           |  Clinician      |         |
|                           |  Workstation    |         |
|                           +-----------------+         |
+-------------------------------------------------------+
           |
           X  No outbound data transfer
           |
```

## 15.2 HIPAA Considerations

- **Audit Trail:** All analyses, reports, annotations, and exports logged with timestamps and user IDs
- **No PHI in Logs:** Logging configured to avoid patient-identifiable information
- **Access Control:** Runs within hospital network; authentication delegated to network perimeter
- **Data Encryption:** PostgreSQL SSL configurable; disk encryption recommended at OS level

### Audit Event Types

| Event Type | Trigger |
|---|---|
| `analysis_completed` | Slide analysis |
| `multi_model_analysis` | Multi-model ensemble |
| `batch_analysis_slide` | Batch slide analysis |
| `batch_analysis_async_completed` | Async batch completed |
| `uncertainty_analysis_completed` | MC Dropout analysis |
| `report_generated` | MedGemma report |
| `pdf_exported` | PDF export |
| `annotation_created` | Annotation created |
| `annotation_deleted` | Annotation deleted |
| `visual_search` | Image-to-image search |
| `patch_classification` | Few-shot classification |
| `outlier_detection` | Outlier tissue detection |

## 15.3 Research-Only Disclaimers

Every report includes mandatory safety statements. The PDF export includes a prominent header warning: "UNCALIBRATED MODEL - RESEARCH USE ONLY". Prohibited phrase validation prevents the system from making direct treatment recommendations.

---

# 16. Performance Benchmarks

## 16.1 Startup Time

| Component | Duration |
|---|---|
| TransMIL Loading (5 models) | 2.1s |
| MedGemma Loading + Warmup | ~90s |
| MedSigLIP Loading | 9.7s |
| FAISS Index Build (208 slides) | 3.2s |
| PostgreSQL Init | 4.8s |
| **Total** | **~120s** |

## 16.2 Per-Slide Analysis

| Operation | Latency |
|---|---|
| Load embeddings (.npy) | 5-15ms |
| TransMIL single model | 20-50ms |
| Multi-model (5 models) | 100-250ms |
| Evidence patch selection (top-8) | <1ms |
| FAISS similar case search | 2-5ms |
| Heatmap generation (first, per-model) | 50-100ms |
| Heatmap serving (cached) | <5ms |
| Semantic search (5 queries) | 100-300ms |
| Outlier detection | 10-50ms |
| Few-shot classification | 50-200ms |
| MedGemma report | ~20s (GPU) |
| **Full analysis (no report)** | **~200ms** |
| **Full analysis (with report)** | **10-120s** |

## 16.3 GPU Memory Usage

| Model | VRAM | Precision |
|---|---|---|
| MedGemma 4B | ~8 GB | bfloat16 |
| MedSigLIP | ~800 MB | fp16 |
| TransMIL (5 models) | ~200 MB | float32 |
| FAISS Index | CPU only | float32 |
| **Total GPU** | **~9 GB** | |

## 16.4 Database Performance

| Query | Response Time |
|---|---|
| List 208 slides (PostgreSQL) | 2-5ms |
| List 208 slides (flat-file fallback) | 30-60s |
| Cached result lookup | 0.8ms |
| Annotation CRUD | <2ms |

## 16.5 TransMIL Model Performance

| Metric | Value |
|---|---|
| Best single-model AUC (optimized threshold) | 0.879 |
| Full-dataset AUC (platinum sensitivity) | 0.907 |
| Optimized threshold (Youden J) | 0.9229 |
| Sensitivity | 84.6% |
| Specificity | 91.2% |
| Cached result lookup | 0.8ms |

---

# 17. Mac Mini Deployment Feasibility

## 17.1 Overview

Enso Atlas is designed for on-premise deployment on consumer hardware. A modern Mac mini (M4 Pro/Max with 16-32 GB unified memory) can run the complete system:

## 17.2 Model Memory Requirements

| Model | Memory Required | Notes |
|---|---|---|
| Path Foundation | ~2 GB | TensorFlow on CPU -- works natively on Apple Silicon |
| TransMIL (5 models) | ~200 MB | PyTorch MPS or CPU, 3.2M params each |
| MedGemma 4B | ~8 GB (bfloat16) | Fits in 16 GB unified memory via MPS |
| MedSigLIP | ~3 GB | SigLIP-so400m full model |
| FAISS Index | ~50 MB | 208 slides, CPU-only |
| PostgreSQL | ~200 MB | Standard footprint |
| **Total** | **~13.5 GB** | Fits in 16 GB Mac mini with headroom |

## 17.3 Performance Expectations

| Operation | DGX Spark (Blackwell) | Mac mini (M4 Pro) |
|---|---|---|
| Multi-model inference (5 models) | 100-250ms | 500ms-2s (MPS) |
| MedGemma report generation | ~20s | 30-60s (MPS) |
| Path Foundation embedding (64 patches) | 2.5s (CPU) | 3-5s (CPU) |
| Heatmap generation | 50-100ms | 100-200ms |
| PostgreSQL queries | 2-5ms | 2-5ms |

## 17.4 Deployment Configuration

For Mac mini deployment:
- Use `device: "mps"` for PyTorch models (MedGemma, TransMIL)
- Path Foundation remains on CPU (TensorFlow)
- PostgreSQL via Homebrew or Docker
- Frontend via Node.js (native ARM64)
- No Docker GPU passthrough needed -- run directly

## 17.5 Key Advantages

- **Cost:** Mac mini M4 Pro (~$1,600) vs DGX Spark (~$3,999+)
- **Noise:** Silent operation suitable for clinical environments
- **Power:** ~40W vs ~500W
- **Size:** Desktop form factor fits in any office
- **Maintenance:** macOS with automatic updates
- **HIPAA:** Data never leaves the device

---

# 18. Known Limitations and Future Work

## 18.1 Current Limitations

### Class Imbalance
139 non-responders vs 13 responders (10.7:1 ratio). Mitigated with weighted loss and Youden J threshold (0.9229).

### Path Foundation CPU-Only
TensorFlow does not support Blackwell GPUs. Embeddings are pre-computed offline.

### Single Cancer Type
Currently HGSOC platinum sensitivity only. The config-driven project system supports additional cancer types pending training data.

### No FDA Clearance
Research tool only. Predictions are uncalibrated raw sigmoid outputs.

### Semantic Search Cold Start
First MedSigLIP embedding run for a slide takes ~12-14 minutes for ~6,680 patches. Cached after first run.

## 18.2 Planned Improvements

### Short-Term (3-6 months)
- Multi-fold ensemble averaging
- Platt scaling for probability calibration
- GPU-accelerated real-time embedding pipeline
- User authentication and RBAC
- DICOM integration for PACS slide import

### Medium-Term (6-12 months)
- Additional cancer types (lung, breast, colorectal)
- Multimodal integration (H&E + IHC)
- Federated learning
- Active learning for efficient annotation
- Real-time collaborative annotation

### Long-Term (12+ months)
- FDA 510(k) regulatory pathway
- EHR integration
- Prospective clinical validation
- Foundation model fine-tuning

---

# 19. Appendices

## Appendix A: Environment Variables

| Variable | Default | Description |
|---|---|---|
| `DATABASE_URL` | `postgresql://enso:enso_atlas_2024@atlas-db:5432/enso_atlas` | PostgreSQL connection |
| `MIL_ARCHITECTURE` | `transmil` | MIL model type |
| `MIL_THRESHOLD` | (from config) | Classification threshold |
| `MIL_THRESHOLD_CONFIG` | `models/threshold_config.json` | Threshold config |
| `MIL_MODEL_PATH` | (auto) | Model checkpoint path |
| `TRANSFORMERS_OFFLINE` | `0` | Air-gapped mode |
| `HF_HUB_OFFLINE` | `0` | Air-gapped mode |
| `HF_HOME` | `/app/cache/huggingface` | HuggingFace cache |
| `ENSO_CONFIG` | `/app/config/default.yaml` | Config file |
| `NVIDIA_VISIBLE_DEVICES` | `all` | GPU selection |
| `NEXT_PUBLIC_API_URL` | `http://localhost:8003` | Frontend API URL |

## Appendix B: File Tree

```
med-gemma-hackathon/
+-- config/
|   +-- default.yaml
|   +-- projects.yaml                    # Project + model definitions
+-- docker/
|   +-- Dockerfile
|   +-- docker-compose.yaml
+-- frontend/
|   +-- next.config.mjs
|   +-- tailwind.config.ts
|   +-- src/
|       +-- app/
|       |   +-- layout.tsx
|       |   +-- page.tsx                 # Main page (2142 lines)
|       |   +-- slides/page.tsx          # Slide manager
|       +-- components/
|       |   +-- layout/
|       |   |   +-- Header.tsx           # Project switcher, view mode, dark mode
|       |   |   +-- Footer.tsx
|       |   |   +-- UserDropdown.tsx
|       |   +-- panels/
|       |   |   +-- AIAssistantPanel.tsx        (38,056 bytes)
|       |   |   +-- AnalysisControls.tsx
|       |   |   +-- BatchAnalysisPanel.tsx      (43,366 bytes)
|       |   |   +-- CaseNotesPanel.tsx
|       |   |   +-- EvidencePanel.tsx
|       |   |   +-- ModelPicker.tsx
|       |   |   +-- MultiModelPredictionPanel.tsx
|       |   |   +-- OncologistSummaryView.tsx
|       |   |   +-- OutlierDetectorPanel.tsx    (11,988 bytes)
|       |   |   +-- PatchClassifierPanel.tsx    (16,135 bytes)
|       |   |   +-- PathologistView.tsx         (30,114 bytes)
|       |   |   +-- PredictionPanel.tsx
|       |   |   +-- QuickStatsPanel.tsx
|       |   |   +-- ReportPanel.tsx
|       |   |   +-- SemanticSearchPanel.tsx
|       |   |   +-- SimilarCasesPanel.tsx
|       |   |   +-- SlideSelector.tsx           (25,527 bytes)
|       |   |   +-- UncertaintyPanel.tsx
|       |   +-- viewer/
|       |   |   +-- WSIViewer.tsx               (61,161 bytes)
|       |   +-- slides/
|       |   |   +-- FilterPanel.tsx
|       |   |   +-- SlideGrid.tsx
|       |   |   +-- SlideTable.tsx
|       |   |   +-- BulkActions.tsx
|       |   |   +-- SlideModals.tsx
|       |   +-- modals/
|       |   |   +-- PatchZoomModal.tsx
|       |   |   +-- KeyboardShortcutsModal.tsx
|       |   |   +-- SettingsModal.tsx
|       |   |   +-- SystemStatusModal.tsx
|       |   +-- demo/
|       |   |   +-- DemoMode.tsx
|       |   +-- ui/
|       |       +-- Badge, Button, Card, Logo, NetworkStatus,
|       |           PredictionGauge, ProgressStepper, Skeleton,
|       |           Slider, Spinner, Toast, Toggle
|       +-- contexts/
|       |   +-- ProjectContext.tsx
|       +-- hooks/
|       |   +-- useAnalysis.ts
|       |   +-- useKeyboardShortcuts.ts
|       +-- lib/
|       |   +-- api.ts                         (2,625 lines)
|       |   +-- pdfExport.ts
|       |   +-- utils.ts
|       +-- types/
|           +-- index.ts                       (561 lines)
+-- models/
|   +-- transmil.py
|   +-- transmil_best.pt
|   +-- threshold_config.json
+-- scripts/
|   +-- train_transmil.py
|   +-- embed_level0_pipelined.py
|   +-- multi_model_inference.py
|   +-- optimize_threshold.py
|   +-- download_ovarian_fixed.py
+-- src/enso_atlas/
|   +-- api/
|   |   +-- main.py                        (6,119 lines)
|   |   +-- database.py                    (1,234 lines)
|   |   +-- projects.py
|   |   +-- project_routes.py
|   |   +-- batch_tasks.py
|   |   +-- batch_embed_tasks.py
|   |   +-- report_tasks.py
|   |   +-- embedding_tasks.py
|   |   +-- pdf_export.py
|   |   +-- slide_metadata.py
|   +-- agent/
|   |   +-- workflow.py                    (1,227 lines)
|   |   +-- routes.py
|   +-- llm/
|   |   +-- chat.py                        (RAG-based chat)
|   +-- embedding/
|   |   +-- embedder_pathfound.py
|   |   +-- medsiglip.py
|   |   +-- embedder.py
|   +-- evidence/
|   |   +-- generator.py
|   +-- mil/
|   |   +-- clam.py
|   +-- reporting/
|   |   +-- medgemma.py                    (908 lines)
|   |   +-- decision_support.py
|   +-- config.py
|   +-- wsi/
|       +-- processor.py
+-- data/
|   +-- labels.csv
|   +-- embeddings/
|   |   +-- level0/                        (208 x .npy files)
|   |   +-- heatmap_cache/                 (cached PNG heatmaps)
|   |   +-- medsiglip_cache/               (cached MedSigLIP embeddings)
|   |   +-- thumbnail_cache/               (cached slide thumbnails)
|   +-- tcga_full/
|       +-- slides/                        (208 .svs files)
|       +-- labels.csv
+-- outputs/                               (TransMIL training outputs)
+-- tests/
+-- docs/
    +-- screenshots/
    +-- reproduce.md
```

## Appendix C: Key Design Decisions

### 1. Raw SQL over ORM
asyncpg with raw SQL for maximum performance and query transparency. No migration framework for small schema.

### 2. Coverage-Based Heatmap Alignment
Heatmap dimensions use `ceil(dim/224)*224` to ensure pixel-perfect alignment with the 224px patch grid. Coverage dimensions are returned as response headers.

### 3. Disk-Based Heatmap Cache
Per-model heatmaps cached to PNG files. First generation takes 50-100ms; subsequent requests serve cached files in <5ms.

### 4. Canvas-Based Overlays vs OSD Overlays
Outlier and classifier heatmaps use a separate HTML canvas rather than OSD's `addSimpleImage`. This allows independent toggle/opacity control and avoids conflicts with the attention heatmap overlay.

### 5. Imperative Scale Bar Updates
Direct DOM manipulation for the scale bar bypasses React's reconciliation on every animation frame, preventing jank during continuous zoom/pan.

### 6. Template Report Fallback
When MedGemma fails or times out, a template-based report preserving real attention weights and coordinates ensures users always receive actionable output.

### 7. FAISS IndexFlatIP for Similar Cases
Exact inner product search on L2-normalized mean embeddings (cosine similarity). Acceptable for 208 slides; switch to IndexIVF at ~10,000+ slides.

## Appendix D: Error Codes

| HTTP Code | Error | Resolution |
|---|---|---|
| 400 | Bad Request / LEVEL0_EMBEDDINGS_REQUIRED | Check request format or generate level 0 embeddings |
| 404 | Slide/Session/Task not found | Verify ID exists |
| 500 | Prediction/PDF/Embedding failed | Check GPU memory, restart server |
| 503 | Model not loaded / DB unavailable | Wait for startup (~120s) or check container status |

---

# Document Revision History

| Version | Date | Author | Changes |
|---|---|---|---|
| 1.0.0 | 2025-02-06 | Enso Labs | Initial specification |
| 2.0.0 | 2025-02-10 | Enso Labs | Complete revamp: added outlier detector, few-shot classifier, patch grid overlay, canvas-based overlays, annotation system (SVG + PostgreSQL), batch embedding, heatmap caching, coverage-based alignment, real-time scale bar, resizable panels, dark mode, Mac mini feasibility, Tailscale Funnel, schema v5, 80+ API endpoints, updated architecture diagrams, all current features |

---

*This document covers approximately 30,000 lines of Python backend code and 15,000 lines of TypeScript frontend code comprising the Enso Atlas platform.*
